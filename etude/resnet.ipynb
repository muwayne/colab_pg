{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Device configuration for Apple chips\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(\n",
    "    dataset_name,\n",
    "    data_dir,\n",
    "    batch_size,\n",
    "    random_seed=42,\n",
    "    valid_size=0.1,\n",
    "    shuffle=True,\n",
    "    test=False,\n",
    "):\n",
    "    # Dataset-specific normalization values\n",
    "    if dataset_name == \"CIFAR10\":\n",
    "        normalize = transforms.Normalize(\n",
    "            mean=[0.4914, 0.4822, 0.4465],\n",
    "            std=[0.2023, 0.1994, 0.2010],\n",
    "        )\n",
    "        resize_dim = (224, 224) # Original CIFAR10 size is 32x32\n",
    "    elif dataset_name == \"CIFAR100\":\n",
    "        normalize = transforms.Normalize(\n",
    "            mean=[0.5071, 0.4867, 0.4408],\n",
    "            std=[0.2675, 0.2565, 0.2761],\n",
    "        )\n",
    "        resize_dim = (224, 224) # Original CIFAR100 size is 32x32\n",
    "    elif dataset_name == \"TinyImageNet\":\n",
    "        normalize = transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "        )\n",
    "        resize_dim = (64, 64)  # Original Tiny ImageNet size is 64x64\n",
    "    elif dataset_name == \"StanfordDogs\":\n",
    "        normalize = transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225],\n",
    "        )\n",
    "        resize_dim = (\n",
    "            224,\n",
    "            224,\n",
    "        )  # Images will be resized to 224x224 for ResNet-like models\n",
    "    else:\n",
    "        raise ValueError(f\"Dataset {dataset_name} not supported.\")\n",
    "\n",
    "    # Define transformations: Resize and normalize\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(resize_dim),  # Resize depending on the dataset\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Choose the dataset\n",
    "    if dataset_name in [\"CIFAR10\", \"CIFAR100\"]:\n",
    "        dataset_cls = datasets.__dict__[dataset_name]\n",
    "    elif dataset_name == \"TinyImageNet\":\n",
    "        dataset_cls = datasets.ImageFolder  # Tiny ImageNet is structured with folders\n",
    "    elif dataset_name == \"StanfordDogs\":\n",
    "        dataset_cls = (\n",
    "            datasets.ImageFolder\n",
    "        )  # Stanford Dogs is also structured with folders\n",
    "    else:\n",
    "        raise ValueError(f\"Dataset {dataset_name} not supported.\")\n",
    "\n",
    "    # Handle test mode\n",
    "    if test:\n",
    "        if dataset_name in [\"CIFAR10\", \"CIFAR100\"]:\n",
    "            dataset = dataset_cls(\n",
    "                root=data_dir,\n",
    "                train=False,\n",
    "                download=True,\n",
    "                transform=transform,\n",
    "            )\n",
    "        else:\n",
    "            dataset = dataset_cls(\n",
    "                root=os.path.join(\n",
    "                    data_dir, \"test\" if dataset_name == \"TinyImageNet\" else \"val\"\n",
    "                ),\n",
    "                transform=transform,\n",
    "            )\n",
    "\n",
    "        test_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "        return test_loader\n",
    "\n",
    "    # Load train dataset\n",
    "    if dataset_name in [\"CIFAR10\", \"CIFAR100\"]:\n",
    "        train_dataset = dataset_cls(\n",
    "            root=data_dir,\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transform,\n",
    "        )\n",
    "\n",
    "        valid_dataset = dataset_cls(\n",
    "            root=data_dir,\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transform,\n",
    "        )\n",
    "    else:\n",
    "        train_dataset = dataset_cls(\n",
    "            root=os.path.join(data_dir, \"train\"),\n",
    "            transform=transform,\n",
    "        )\n",
    "\n",
    "        valid_dataset = dataset_cls(\n",
    "            root=os.path.join(data_dir, \"train\"),\n",
    "            transform=transform,\n",
    "        )\n",
    "\n",
    "    # Split the train dataset into train and validation\n",
    "    num_train = len(train_dataset)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "    # Create samplers for train and validation\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, sampler=train_sampler\n",
    "    )\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset, batch_size=batch_size, sampler=valid_sampler\n",
    "    )\n",
    "\n",
    "    return (train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "\n",
    "# Initialize TensorBoard writer\n",
    "log_dir = \"./runs/resnet_experiment_\" + time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "\n",
    "# Hook function to capture the activations\n",
    "def hook_fn(module, input, output):\n",
    "    writer.add_histogram(f\"{module.__class__.__name__}_activations\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock_A(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock_A, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size=3,\n",
    "                stride=stride,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                out_channels,\n",
    "                out_channels,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        # automatically create downsample layer if needed\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Register hooks on conv1 and conv2 to visualize intermediate activations\n",
    "        # self.conv1[0].register_forward_hook(hook_fn)\n",
    "        # self.conv2[0].register_forward_hook(hook_fn)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock_B(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bottleneck_rate=4, stride=1):\n",
    "        super(ResidualBlock_B, self).__init__()\n",
    "\n",
    "        # Calculate the number of mid_channels using the bottleneck rate\n",
    "        mid_channels = out_channels // bottleneck_rate\n",
    "\n",
    "        # 1x1 convolution (to reduce dimensionality)\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels, mid_channels, kernel_size=1, stride=stride, bias=False\n",
    "            ),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # 3x3 convolution (spatial convolution)\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                mid_channels,\n",
    "                mid_channels,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # 1x1 convolution (to restore dimensionality)\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "        # If the input and output sizes don't match, we need a downsample layer\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels, out_channels, kernel_size=1, stride=stride, bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Register hooks on conv1 and conv2 to visualize intermediate activations\n",
    "        # self.conv1[0].register_forward_hook(hook_fn)\n",
    "        # self.conv2[0].register_forward_hook(hook_fn)\n",
    "        # self.conv3[0].register_forward_hook(hook_fn)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        # Forward pass through the three convolutional layers\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "\n",
    "        # Apply downsample if needed\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        # Add the residual (skip connection)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet34(nn.Module):\n",
    "    def __init__(self, residual_block, num_classes=10):\n",
    "        super(ResNet34, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer0 = self._make_layer(residual_block, 64, 64, 3)\n",
    "        self.layer1 = self._make_layer(residual_block, 64, 128, 4, init_stride=2)\n",
    "        self.layer2 = self._make_layer(residual_block, 128, 256, 6, init_stride=2)\n",
    "        self.layer3 = self._make_layer(residual_block, 256, 512, 3, init_stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(\n",
    "        self, residual_block, in_channels, out_channels, num_blocks, init_stride=1\n",
    "    ):\n",
    "        layers = [residual_block(in_channels, out_channels, init_stride)]\n",
    "        for i in range(1, num_blocks):\n",
    "            layers.append(residual_block(out_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, residual_block, num_classes=10):\n",
    "        super(ResNet50, self).__init__()\n",
    "\n",
    "        # Initial Convolutional Layer (same as ResNet-34)\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # ResNet-50 Specific Layer Configurations\n",
    "        self.layer1 = self._make_layer(residual_block, 64, 256, 3)  # 3 blocks\n",
    "        self.layer2 = self._make_layer(\n",
    "            residual_block, 256, 512, 4, stride=2\n",
    "        )  # 4 blocks\n",
    "        self.layer3 = self._make_layer(\n",
    "            residual_block, 512, 1024, 6, stride=2\n",
    "        )  # 6 blocks\n",
    "        self.layer4 = self._make_layer(\n",
    "            residual_block, 1024, 2048, 3, stride=2\n",
    "        )  # 3 blocks\n",
    "\n",
    "        # AdaptiveAvgPool2d for any input size\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "    def _make_layer(\n",
    "        self, residual_block, in_channels, out_channels, num_blocks, stride=1\n",
    "    ):\n",
    "        layers = [residual_block(in_channels, out_channels, stride)]\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(residual_block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(data_loader, model, device=\"cpu\"):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            del images, labels, outputs\n",
    "            torch.cuda.empty_cache()\n",
    "    model.train()  # Set the model back to training mode\n",
    "    return total, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_checkpoint_dir(checkpoint_dir):\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)  # Ensure checkpoint directory exists\n",
    "\n",
    "\n",
    "def train(\n",
    "    num_epochs,\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device,\n",
    "    writer,\n",
    "    checkpoint_dir=\"./checkpoints\",\n",
    "):\n",
    "    # Get the model class name dynamically\n",
    "    model_class_name = model.__class__.__name__\n",
    "\n",
    "    # Create the directory based on model class name\n",
    "    checkpoint_dir = os.path.join(checkpoint_dir, model_class_name)\n",
    "    create_checkpoint_dir(checkpoint_dir)\n",
    "\n",
    "    # Train the model\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "\n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            iter_start = time.time()\n",
    "\n",
    "            # Move tensors to the configured device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # calculate the iteration latency\n",
    "            iter_latency = time.time() - iter_start\n",
    "            writer.add_scalar(\n",
    "                \"Latency/iteration\", iter_latency, epoch * len(train_loader) + batch_idx\n",
    "            )\n",
    "            writer.add_scalar(\n",
    "                \"Loss/train\", loss.item(), epoch * len(train_loader) + batch_idx\n",
    "            )\n",
    "\n",
    "            # Clear memory to avoid GPU memory overflow\n",
    "            del images, labels, outputs\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        # Log epoch latency\n",
    "        epoch_latency = time.time() - epoch_start_time\n",
    "        writer.add_scalar(\"Latency/epoch\", epoch_latency, epoch)\n",
    "        print(\n",
    "            f\"Epoch [{epoch+1}/{num_epochs}] finished in {epoch_latency:.2f} seconds.\"\n",
    "        )\n",
    "\n",
    "        # Validation\n",
    "        total, correct = eval(valid_loader, model, device)\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Accuracy on validation images after epoch {epoch+1}: {accuracy:.2f}%\")\n",
    "        writer.add_scalar(\"Accuracy/validation\", accuracy, epoch)\n",
    "\n",
    "        # Save model checkpoint\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"model_epoch_{epoch+1}.pth\")\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f\"Model checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "    writer.flush()  # Flush all pending events to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./dataset/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1343488/169001437 [00:29<3:08:32, 14820.61it/s]"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "dataset_name = \"CIFAR100\"\n",
    "num_classes = 100\n",
    "batch_size = 64\n",
    "num_epochs = 50\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "train_loader, valid_loader = data_loader(\n",
    "    dataset_name=dataset_name, data_dir=\"./dataset\", batch_size=batch_size\n",
    ")\n",
    "\n",
    "# model = ResNet34(ResidualBlock_A, num_classes=num_classes).to(device)\n",
    "model = ResNet50(ResidualBlock_B, num_classes=num_classes).to(device)\n",
    "\n",
    "# Define a dummy input to pass through the model\n",
    "dummy_input = torch.randn(1, 3, 224, 224).to(\n",
    "    device\n",
    ")  # Example input of shape (batch_size, channels, height, width)\n",
    "\n",
    "# Log the model graph to TensorBoard\n",
    "writer.add_graph(model, dummy_input)\n",
    "writer.flush()\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(\n",
    "#     model.parameters(), lr=learning_rate, weight_decay=0.001, momentum=0.9\n",
    "# )\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.001)\n",
    "\n",
    "# Learning rate scheduler (reduce LR by 0.1 every 30 epochs)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "\n",
    "train(\n",
    "    num_epochs=num_epochs,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    writer=writer,\n",
    "    checkpoint_dir=\"./checkpoints\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "test_loader = data_loader(\n",
    "    dataset_name=dataset_name, data_dir=\"./dataset\", batch_size=batch_size, test=True\n",
    ")\n",
    "\n",
    "# Evaluate on the test dataset\n",
    "total, correct = eval(test_loader, model, device)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy of the network on the {total} test images: {accuracy:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
